import streamlit as st
import pandas as pd
import os
import joblib
from preprocessing import preprocess_data
from feature_engineering import add_features, segment_customers,calculate_risk_metrics
from modeling import  train_model,format_classification_report
from visualization import plot_customer_segments, generate_summary_report,generate_risk_summary,plot_risk_heatmap,plot_default_rate_by_category,plot_distribution,plot_correlation_heatmap,plot_credit_utilization_vs_default,plot_customer_segments_summary

BASE_DIR = os.path.dirname(os.path.abspath(__file__))

# ==================== Streamlit App ====================
# C·∫•u h√¨nh giao di·ªán
st.set_page_config(page_title="Qu·∫£n l√Ω r·ªßi ro t√≠n d·ª•ng", layout="wide")
DEFAULT_DATA_PATH = os.path.join(BASE_DIR, 'UCI_Credit_Card.csv')
# Ti√™u ƒë·ªÅ ch√≠nh
st.title("Qu·∫£n l√Ω r·ªßi ro t√≠n d·ª•ng")
results = []

# ƒê∆∞·ªùng d·∫´n ƒë·∫øn file ƒë√£ x·ª≠ l√Ω
PROCESSED_DATA_PATH = os.path.join(BASE_DIR,"processed_credit_data.csv")
# Ki·ªÉm tra n·∫øu file ƒë√£ t·ªìn t·∫°i
if os.path.exists(PROCESSED_DATA_PATH):
    processed_data = pd.read_csv(PROCESSED_DATA_PATH)
else:
    st.error("File d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω kh√¥ng t·ªìn t·∫°i. H√£y ch·∫°y script x·ª≠ l√Ω d·ªØ li·ªáu tr∆∞·ªõc.")

# ƒê·ªçc d·ªØ li·ªáu
def load_default_data():
    data = pd.read_csv(DEFAULT_DATA_PATH)
    processed_data = preprocess_data(data)
    processed_data = add_features(processed_data)
    processed_data = segment_customers(processed_data)
    processed_data = calculate_risk_metrics(processed_data)
    return processed_data
processed_data = load_default_data()
st.sidebar.header("T·∫£i l√™n d·ªØ li·ªáu kh√°ch h√†ng m·ªõi")
uploaded_file = st.sidebar.file_uploader("Ch·ªçn file kh√°ch h√†ng m·ªõi (CSV)", type=["csv"])

# Thay th·∫ø ƒëo·∫°n n√†y b·∫±ng logic m·ªõi d√πng m√¥ h√¨nh
# T·∫£i m√¥ h√¨nh ƒë√£ l∆∞u
reg_model_file = "risk_management\modelfile\multioutput_model.pkl"
clf_model_file = "risk_management\modelfile\classification_model.pkl"
reg_model = joblib.load(reg_model_file)
clf_model = joblib.load(clf_model_file)
# Giao di·ªán t·∫£i d·ªØ li·ªáu kh√°ch h√†ng m·ªõi
if uploaded_file:
    st.sidebar.success("D·ªØ li·ªáu kh√°ch h√†ng m·ªõi ƒë√£ ƒë∆∞·ª£c t·∫£i l√™n!")
    # ƒê·ªçc file kh√°ch h√†ng m·ªõi
    new_customer_data = pd.read_csv(uploaded_file)
    st.write("### D·ªØ li·ªáu kh√°ch h√†ng m·ªõi:")
    st.dataframe(new_customer_data)

    # T√≠nh c√°c ch·ªâ s·ªë r·ªßi ro
    features = ["LIMIT_BAL","SEX","EDUCATION","MARRIAGE","AGE","PAY_0","PAY_2","PAY_3","PAY_4","PAY_5","PAY_6","BILL_AMT1","BILL_AMT2","BILL_AMT3","BILL_AMT4","BILL_AMT5","BILL_AMT6","PAY_AMT1","PAY_AMT2","PAY_AMT3","PAY_AMT4","PAY_AMT5","PAY_AMT6","Credit_Utilization", "Repayment_Trend"]
    new_customer_data = preprocess_data(new_customer_data)
    new_customer_data = add_features(new_customer_data)
    new_customer_data = segment_customers(new_customer_data)
    #new_customer_data = calculate_risk_metrics(new_customer_data)
    input_data = new_customer_data[features]
    
    # D·ª± ƒëo√°n c√°c ch·ªâ s·ªë
    predictions = reg_model.predict(input_data)
    new_customer_data[["PD", "LGD", "EAD", "EL"]] = predictions
    classification = clf_model.predict(input_data)
    new_customer_data["default"] = classification
    new_customer_data["default"] = new_customer_data["default"].replace({0: "Kh√¥ng v·ª° n·ª£", 1: "V·ª° n·ª£"})

    # Hi·ªÉn th·ªã k·∫øt qu·∫£
    st.write("### K·∫øt qu·∫£ d·ª± ƒëo√°n:")
    st.dataframe(new_customer_data[["PD", "LGD", "EAD", "EL","default"]])
else:
    st.info("H√£y t·∫£i l√™n file CSV ch·ª©a d·ªØ li·ªáu kh√°ch h√†ng m·ªõi ƒë·ªÉ ƒë√°nh gi√°.")
if results:
    st.write("### K·∫øt qu·∫£ ƒë√°nh gi√° r·ªßi ro (m·∫∑c ƒë·ªãnh)")
    st.dataframe(pd.DataFrame(results))
    # T√≠nh to√°n c√°c ch·ªâ s·ªë r·ªßi ro t√≠n d·ª•ng
processed_data = calculate_risk_metrics(processed_data)
filtered_data = processed_data[processed_data['default'] == 1]
st.write("### B√°o c√°o r·ªßi ro t√≠n d·ª•ng")
risk_summary = generate_risk_summary(processed_data)
for key, value in risk_summary.items():
    st.write(f"{key}: {value:.2f}")
# Tab ch·ª©c nƒÉng
tab1, tab2, tab3 = st.tabs(["üìä T·ªïng quan", "üìà Ph√¢n t√≠ch & D·ª± b√°o", "ü§ñ Hu·∫•n luy·ªán m√¥ h√¨nh"])
# Tab 1: T·ªïng quan
with tab1:
    st.header("B√°o c√°o t·ªïng h·ª£p")
    st.write("### Danh s√°ch kh√°ch h√†ng v·ª° n·ª£")
    generate_summary_report(processed_data)
    
    # Hi·ªÉn th·ªã b·∫£ng d·ªØ li·ªáu m·∫´u
    st.dataframe(filtered_data)
# Tab 2: Ph√¢n t√≠ch & D·ª± b√°o
with tab2:
    st.header("Ph√¢n t√≠ch ph√¢n kh√∫c kh√°ch h√†ng")
    st.pyplot(plot_customer_segments(processed_data))
    st.header("T·ªâ l·ªá v·ª° n·ª£ t·ª´ng ph√¢n kh√∫c")
    st.pyplot(plot_customer_segments_summary(processed_data))
    st.header("T∆∞∆°ng quan gi·ªØa c√°c y·∫øu t·ªë t·ª± nhi√™n")
    features_heatmap = ["default","LIMIT_BAL","SEX","EDUCATION","MARRIAGE","AGE"]
    st.pyplot(plot_correlation_heatmap(processed_data,features_heatmap))
    st.header("Ph√¢n ph·ªëi kh·∫£ nƒÉng v·ª° n·ª£ theo tu·ªïi")
    st.pyplot(plot_distribution(filtered_data,"AGE"))
    st.header("T·ªâ l·ªá v·ª° n·ª£ theo h·ªçc v·∫•n")
    st.pyplot(plot_default_rate_by_category(processed_data,'EDUCATION', top_n=5))
    st.header("Ph√¢n ph·ªëi kh·∫£ nƒÉng v·ª° n·ª£ theo t√≠n d·ª•ng")
    st.pyplot(plot_credit_utilization_vs_default(processed_data))
    st.header("T∆∞∆°ng quan gi·ªØa c√°c ch·ªâ s·ªë r·ªßi ro")
    heatmap_fig = plot_risk_heatmap(processed_data)
    st.pyplot(heatmap_fig)
    # Tab 3: Hu·∫•n luy·ªán m√¥ h√¨nh
with tab3:
    st.header("K·∫øt qu·∫£ hu·∫•n luy·ªán m√¥ h√¨nh")
    # Hu·∫•n luy·ªán m√¥ h√¨nh v√† l·∫•y b√°o c√°o
    with st.spinner("ƒêang hu·∫•n luy·ªán m√¥ h√¨nh..."):
        classification_results, regression_results = train_model(processed_data)
    
    # Hi·ªÉn th·ªã k·∫øt qu·∫£ m√¥ h√¨nh ph√¢n lo·∫°i
    st.subheader("B√°o c√°o ph√¢n lo·∫°i:")
    classification_report_str = classification_results["classification_report"]
    auc_roc = classification_results["auc_roc_class"]
    
    # ƒê·ªãnh d·∫°ng v√† hi·ªÉn th·ªã b√°o c√°o ph√¢n lo·∫°i
    report_df = format_classification_report(classification_report_str)
    st.dataframe(report_df)  # Hi·ªÉn th·ªã d∆∞·ªõi d·∫°ng b·∫£ng
    
    # Hi·ªÉn th·ªã ch·ªâ s·ªë AUC-ROC
    st.subheader("Ch·ªâ s·ªë AUC-ROC:")
    st.metric(label="AUC-ROC", value=f"{auc_roc:.4f}")
    
    # Hi·ªÉn th·ªã k·∫øt qu·∫£ m√¥ h√¨nh h·ªìi quy
    st.subheader("B√°o c√°o h·ªìi quy:")
    regression_report_df = pd.DataFrame({
        "Ch·ªâ s·ªë": ["Mean Squared Error (MSE)", "R-squared (R¬≤)", "Mean Absolute Error (MAE)"],
        "Gi√° tr·ªã": [regression_results["MSE"], regression_results["R¬≤"], regression_results["MAE"]]
    })
    st.dataframe(regression_report_df)  # Hi·ªÉn th·ªã b·∫£ng c√°c ch·ªâ s·ªë h·ªìi quy
    
    st.success("ƒê√£ hu·∫•n luy·ªán v√† ƒë√°nh gi√° c·∫£ hai m√¥ h√¨nh.")



